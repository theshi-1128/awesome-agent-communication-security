# Risks from L3
**Note**: Due to the forward-looking nature of this paper, the risks we mentioned include both **the proposed ones** and **potential directions that have not been studied**. As a result, some risks may lack a concrete list of papers, we hope our paper can inspire these directions.

# R1: Memory-related Risks
- [2025/09] **[A survey on the memory mechanism of large language model based agents](https://dl.acm.org/doi/abs/10.1145/3748302)**
- [2025/10] **[A practical memory injection attack against llm agents](https://arxiv.org/abs/2503.03704)**
- [2024] **[Agentpoison: Red-teaming llm agents via poisoning memory or knowledge bases](https://proceedings.neurips.cc/paper_files/paper/2024/hash/eb113910e9c3f6242541c1652e30dfd6-Abstract-Conference.html)**
- [2024/01] **[Badchain: Backdoor chain-of-thought prompting for large language models](https://arxiv.org/abs/2401.12242)**
- [2024/08] **[The good and the bad: Exploring privacy issues in retrieval-augmented generation (rag)](https://aclanthology.org/2024.findings-acl.267/)**
- [2025/08] **[Rag-thief: Scalable extraction of private data from retrievalaugmented generation applications with agent-based attacks](https://arxiv.org/abs/2411.14110)**
- [2025/07] **[Unveiling privacy risks in llm agent memory](https://aclanthology.org/2025.acl-long.1227/)**

# R2: Knowledge-related Risks
- [2025/10] **[Phantom: General trigger attacks on retrieval augmented language generation](https://arxiv.org/abs/2405.20485)**
- [2024/07] **[Black-box opinion manipulation attacks to retrieval-augmented generation of large language models](https://arxiv.org/abs/2407.13757)**
- [2025/06] **[Badrag: Identifying vulnerabilities in retrieval augmented generation of large language models](https://arxiv.org/abs/2406.00083)**
- [2025/08] **[Poisonedrag: Knowledge corruption attacks to retrieval-augmented generation of large language models](https://www.usenix.org/conference/usenixsecurity25/presentation/zou-poisonedrag)**
- [2025/04] **[Poison-rag: Adversarial data poisoning attacks on retrieval-augmented generation in recommender systems](https://link.springer.com/chapter/10.1007/978-3-031-88717-8_18)**

# R3: Real-world Damage
- [2023/10] **[Poisoning retrieval corpora by injecting adversarial passages](https://arxiv.org/abs/2310.19156)**
- [2025/01] **[Psyche: A multi-faceted patient simulation framework for evaluation of psychiatric assessment conversational agents](https://arxiv.org/abs/2501.01594)**
- [2024/07] **[Flooding spread of manipulated knowledge in llm-based multiagent communities](https://arxiv.org/abs/2407.07791)**
- [2024/09] **[Prompt infection: Llm-to-llm prompt injection within multi-agent systems](https://arxiv.org/abs/2410.07283)**
- [2025/07] **[We urgently need privilege management in mcp: A measurement of api usage in mcp ecosystems](https://arxiv.org/abs/2507.06250)**
- [2025/02] **[Exploring the security threats of knowledge base poisoning in retrieval-augmented code generation](https://arxiv.org/abs/2502.03233)**
