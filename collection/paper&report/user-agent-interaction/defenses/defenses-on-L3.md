# Defenses on L3

## D1: Defense for Text-based Attacks
- [2024/02] **[Defending LLMs against Jailbreaking Attacks via Backtranslation](https://arxiv.org/abs/2402.16459)**
- [2024/01] **[Intention Analysis Makes LLMs A Good Jailbreak Defender](https://aclanthology.org/2025.coling-main.199/)**
- [2023/09] **[Baseline Defenses for Adversarial Attacks Against Aligned Language Models](https://arxiv.org/abs/2309.00614)**
- [2023/12] **[Llama Guard: LLM-based Input-Output Safeguard for Human-AI Conversations](https://arxiv.org/abs/2312.06674)**
- [2024/09] **[GenTel-Safe: A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks](https://arxiv.org/abs/2409.19521)**
- [2025/04] **[ShieldGemma 2: Robust and Tractable Image Content Moderation](https://arxiv.org/abs/2504.01081)**
- [2024/02] **[ShieldLM: Empowering LLMs as Aligned, Customizable and Explainable Safety Detectors](https://arxiv.org/abs/2402.16444)**
- [2023/09] **[LLM-Fuzzer: Scaling Assessment of Large Language Model Jailbreaks](https://www.usenix.org/conference/usenixsecurity24/presentation/yu-jiahao)**
- [2024/02] **[HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal](https://arxiv.org/abs/2402.04249)**
- [2025/01] **[TrustRAG: Enhancing Robustness and Trustworthiness in Retrieval-Augmented Generation](https://arxiv.org/abs/2501.00879)**



## D2: Defense for Multimodal Attacks
- [2017/11] **[Mitigating Adversarial Effects Through Randomization](https://arxiv.org/abs/1711.01991)**
- [2022/05] **[Diffusion Models for Adversarial Purification](https://arxiv.org/abs/2205.07460)**
- [2019/12] **[Adversarial Examples Are Not Bugs, They Are Features](https://proceedings.neurips.cc/paper/2019/hash/e2c420d928d4bf8ce0ff2ec19b371514-Abstract.html)**
- [2017/05] **[Keeping the Bad Guys Out: Protecting and Vaccinating Deep Learning with JPEG Compression](https://arxiv.org/abs/1705.02900)**
- [2019/03] **[Imperceptible, Robust, and Targeted Adversarial Examples for Automatic Speech Recognition](https://proceedings.mlr.press/v97/qin19a.html)**
- [2024/12] **[Safe-CLIP: Removing NSFW Concepts from Vision-and-Language Models](https://link.springer.com/chapter/10.1007/978-3-031-73668-1_20)**
- [2021/02] **[Learning Transferable Visual Models From Natural Language Supervision](https://proceedings.mlr.press/v139/radford21a)**



## D3: Defense for Privacy Violation
- [2021/03] **[IdentityDP: Differential Private Identification Protection for Face Images](https://link.springer.com/chapter/10.1007/978-3-031-58222-6_5)**
- [2024/09] **[GenTel-Safe: A Unified Benchmark and Shielding Framework for Defending Against Prompt Injection Attacks](https://arxiv.org/abs/2409.19521)**

## D4: Behavior Auditing and Restrictions

## D5: Capability Boundary Control
