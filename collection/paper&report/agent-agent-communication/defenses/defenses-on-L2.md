# Defenses on L2

## D1: Identity Authentication and Capability Verification
- [2024/02] **[Building a secure agentic ai application leveraging googleâ€™s a2a protocol.](https://arxiv.org/abs/2402.16459)**
- [2024/01] **[Enforcing cybersecurity constraints for llm-driven robot agents for online transactions.](https://aclanthology.org/2025.coling-main.199/)**
- [2024/02] **[Are Robust LLM Fingerprints Adversarially Robust?](https://arxiv.org/abs/2402.16459)**
- [2024/01] **[Copyright protection for large language models: A survey of methods, challenges, and trends.](https://aclanthology.org/2025.coling-main.199/)**
- [2024/02] **[Scalable Fingerprinting of Large Language Models.](https://arxiv.org/abs/2402.16459)**
- [2024/01] **[LLM Fingerprinting via Semantically Conditioned Watermarks.](https://aclanthology.org/2025.coling-main.199/)**
- [2024/02] **[FPEdit: Robust LLM Fingerprinting through Localized Parameter Editing.](https://arxiv.org/abs/2402.16459)**
- [2024/01] **[ImF:Implicit Fingerprint for Large Language Models](111111)**
- [2024/01] **[EditMF: Drawing an Invisible Fingerprint for Your Large Language Models.](111111)**
- [2024/01] **[EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint.](111111)**
- [2024/01] **[ Insty: a robust multi-level crossgranularity fingerprint embedding algorithm for multi-turn dialogue in large language models.](111111)**
- [2024/01] **[CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor.](111111)**
- [2024/01] **[PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement.](111111)**
- [2024/01] **[MEraser: An Effective Fingerprint Erasure Approach for Large Language Models. ](111111)**
- [2024/01] **[Fingerprint vector: Enabling scalable and efficient model fingerprint transfer via vector addition](111111)**
- [2024/01] **[Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models.](111111)**
- [2024/01] **[LLMmap: Fingerprinting for Large Language Models.](111111)**
- [2024/01] **[Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation.](111111)**
- [2024/01] **[LLM DNA: Tracing Model Evolution via Functional Representations.](111111)**
- [2024/01] **[Rap-sm: Robust adversarial prompt via shadow models for copyright verification of large language models](111111)**
- [2024/01] **[REEF : Representation Encoding Fingerprints for Large Language Models. ](111111)**



## D2: Behavior Auditing and Responsibility Tracing
- [2024/01] **[Supporting human-ai collaboration in auditing llms with llms. ](111111)**
- [2024/01] **[Auditllm: a tool for auditing large language models using multiprobe approach.](111111)**
- [2024/01] **[Auditing large language models: a three-layered approach.](111111)**
- [2024/01] **[Disclosure audits for llm agents.](111111)**
- [2024/01] **[Scalable auditing for ai safety.](111111)**
- [2024/01] **[Governance in agentic workflows: Leveraging llms as oversight agents.](111111)**
- [2024/01] **[Trail: Trace reasoning and agentic issue localization.](111111)**
- [2024/01] **[Enforcement agents: Enhancing accountability and resilience in multi-agent ai frameworks.](111111)**
- [2024/01] **[Modular speaker architecture: A framework for sustaining responsibility and contextual integrity in multi-agent ai communication.](111111)**
- [2024/01] **[Peerguard: Defending multi-agent systems against backdoor attacks through mutual reasoning.](111111)**
- [2024/01] **[Think twice before you act: Enhancing agent behavioral safety with thought correction.](111111)**


## D3: Causal Tracing and Localization
- [2024/01] **[Atag: Ai-agent application threat assessment with attack graphs.](111111)**
- [2024/01] **[Netsafe: Exploring the topological safety of multi-agent networks.](111111)**

## D4: Defense for Denial of Service
- [2024/01] **[Halo: Hierarchical autonomous logic-oriented orchestration for multi-agent llm systems.](111111)**
- [2024/01] **[Assessing and enhancing the robustness of llmbased multi-agent systems through chaos engineering. ](111111)**

## D5: Defense for Registration Pollution
- [2024/01] **[Zero trust architecture.](111111)**
- [2024/01] **[Saga: A security architecture for governing ai agentic systems.](111111)**

## D6: Defense for SEO Poisoning


## D7: Task Lifecycle Monitoring
- [2024/01] **[Attention knows whom to trust: Attention-based trust management for llm multi-agent systems.](111111)**
- [2024/01] **[G-memory: Tracing hierarchical memory for multiagent systems.](111111)**
- [2024/01] **[An adversary-resistant multi-agent llm system via credibility scoring.](111111)**
