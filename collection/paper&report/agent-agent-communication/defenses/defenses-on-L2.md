# Defenses on L2
**Note**: Due to the forward-looking nature of this paper, the defenses we mentioned include both **the proposed ones** and **potential directions that have not been studied**. As a result, some defenses may lack a concrete list of papers, we hope our paper can inspire these directions.
## D1: Identity Authentication and Capability Verification
- [2025/05] **[Building a secure agentic ai application leveraging googleâ€™s a2a protocol.](https://arxiv.org/pdf/2504.16902v2)**
- [2025/03] **[Enforcing cybersecurity constraints for llm-driven robot agents for online transactions.](https://arxiv.org/abs/2503.15546)**
- [2025/09] **[Are Robust LLM Fingerprints Adversarially Robust?](https://arxiv.org/abs/2509.26598)**
- [2025/08] **[Copyright protection for large language models: A survey of methods, challenges, and trends.](https://arxiv.org/abs/2508.11548)**
- [2025/02] **[Scalable Fingerprinting of Large Language Models.](https://arxiv.org/abs/2502.07760)**
- [2025/10] **[LLM Fingerprinting via Semantically Conditioned Watermarks.](https://arxiv.org/abs/2505.16723)**
- [2025/10] **[FPEdit: Robust LLM Fingerprinting through Localized Parameter Editing.](https://arxiv.org/abs/2508.02092)**
- [2025/08] **[ImF:Implicit Fingerprint for Large Language Models](https://arxiv.org/abs/2503.21805)**
- [2025/08] **[EditMF: Drawing an Invisible Fingerprint for Your Large Language Models.](https://arxiv.org/abs/2508.08836)**
- [2025/09] **[EverTracer: Hunting Stolen Large Language Models via Stealthy and Robust Probabilistic Fingerprint.](https://aclanthology.org/2025.emnlp-main.358/)**
- [2025/07] **[Insty: a robust multi-level crossgranularity fingerprint embedding algorithm for multi-turn dialogue in large language models.](https://www.sciengine.com/SSI/doi/10.1360/SSI-2025-0022)**
- [2025/09] **[CTCC: A Robust and Stealthy Fingerprinting Framework for Large Language Models via Cross-Turn Contextual Correlation Backdoor.](https://aclanthology.org/2025.emnlp-main.356/)**
- [2025/09] **[PREE: Towards Harmless and Adaptive Fingerprint Editing in Large Language Models via Knowledge Prefix Enhancement.](https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.204.pdf)**
- [2025/06] **[MEraser: An Effective Fingerprint Erasure Approach for Large Language Models. ](https://arxiv.org/abs/2506.12551)**
- [2024/09] **[Fingerprint vector: Enabling scalable and efficient model fingerprint transfer via vector addition](https://arxiv.org/abs/2409.08846)**
- [2025/09] **[Unlocking the Effectiveness of LoRA-FP for Seamless Transfer Implantation of Fingerprints in Downstream Models.](https://aclanthology.org/anthology-files/anthology-files/pdf/findings/2025.findings-emnlp.230.pdf)**
- [2025/08] **[LLMmap: Fingerprinting for Large Language Models.](https://www.usenix.org/conference/usenixsecurity25/presentation/pasquini)**
- [2025/10] **[Reading Between the Lines: Towards Reliable Black-box LLM Fingerprinting via Zeroth-order Gradient Estimation.](https://arxiv.org/abs/2510.06605)**
- [2025/09] **[LLM DNA: Tracing Model Evolution via Functional Representations.](https://arxiv.org/abs/2509.24496)**
- [2025/05] **[Rap-sm: Robust adversarial prompt via shadow models for copyright verification of large language models](https://arxiv.org/abs/2505.06304)**
- [2024/10] **[REEF : Representation Encoding Fingerprints for Large Language Models. ](https://arxiv.org/abs/2410.14273)**



## D2: Behavior Auditing and Responsibility Tracing
- [2023/08] **[Supporting human-ai collaboration in auditing llms with llms. ](https://dl.acm.org/doi/abs/10.1145/3600211.3604712)**
- [2024/10] **[Auditllm: a tool for auditing large language models using multiprobe approach.](https://dl.acm.org/doi/abs/10.1145/3627673.3679222)**
- [2023/05] **[Auditing large language models: a three-layered approach.](https://link.springer.com/article/10.1007/s43681-023-00289-2)**
- [2025/09] **[Disclosure audits for llm agents.](https://arxiv.org/abs/2506.10171)**
- [2025/05] **[Scalable auditing for ai safety.](https://www2.eecs.berkeley.edu/Pubs/TechRpts/2025/EECS-2025-56.pdf)**
- [2025/01] **[Governance in agentic workflows: Leveraging llms as oversight agents.](https://openreview.net/forum?id=fP02TFDJh8)**
- [2025/06] **[Trail: Trace reasoning and agentic issue localization.](https://arxiv.org/abs/2505.08638)**
- [2025/04] **[Enforcement agents: Enhancing accountability and resilience in multi-agent ai frameworks.](https://arxiv.org/abs/2504.04070)**
- [2025/06] **[Modular speaker architecture: A framework for sustaining responsibility and contextual integrity in multi-agent ai communication.](https://arxiv.org/abs/2506.01095)**
- [2025/05] **[Peerguard: Defending multi-agent systems against backdoor attacks through mutual reasoning.](https://arxiv.org/abs/2505.11642)**
- [2025/05] **[Think twice before you act: Enhancing agent behavioral safety with thought correction.](https://arxiv.org/abs/2505.11063)**


## D3: Causal Tracing and Localization
- [2025/06] **[Atag: Ai-agent application threat assessment with attack graphs.](https://arxiv.org/abs/2506.02859)**
- [2024/10] **[Netsafe: Exploring the topological safety of multi-agent networks.](https://arxiv.org/abs/2410.15686)**

## D4: Defense for Denial of Service
- [2025/05] **[Halo: Hierarchical autonomous logic-oriented orchestration for multi-agent llm systems.](https://arxiv.org/abs/2505.13516)**
- [2025/04] **[Assessing and enhancing the robustness of llmbased multi-agent systems through chaos engineering. ](https://ieeexplore.ieee.org/abstract/document/11030017)**

## D5: Defense for Registration Pollution
- [2020/08] **[Zero trust architecture.](https://nvlpubs.nist.gov/nistpubs/specialpublications/NIST.SP.800-207.pdf)**
- [2025/08] **[Saga: A security architecture for governing ai agentic systems.](https://arxiv.org/html/2504.21034v2)**

## D6: Defense for SEO Poisoning


## D7: Task Lifecycle Monitoring
- [2025/01] **[Attention knows whom to trust: Attention-based trust management for llm multi-agent systems.](https://arxiv.org/abs/2506.02546)**
- [2025/06] **[G-memory: Tracing hierarchical memory for multiagent systems.](https://arxiv.org/abs/2506.07398)**
- [2025/05] **[An adversary-resistant multi-agent llm system via credibility scoring.](https://arxiv.org/abs/2505.24239)**
